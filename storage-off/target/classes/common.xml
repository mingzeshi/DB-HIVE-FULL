<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- 导入数据的源数据库及库表 配置文件 -->
    <property>
        <name>import.db.config.path</name>
        <value>/server/app/mr/product/ImportConfig.xml</value>
    </property>
	
	<!-- 数据输出配置项 -->
	<property>
        <name>load.hive.config</name>
        <value>hc1,hcP1</value>
    </property>

	<!-- 数据输出到Hive的Location 配置文件 非分区表 -->
	<property>
        <name>hc1.hive</name>
        <value>/server/app/mr/product/LoadToHiveODS.xml</value>
    </property>
	<!-- 数据输出到Hive的Location 配置文件 分区表(P) -->
    <property>
        <name>hcP1.hive</name>
        <value>/server/app/mr/product/LoadToHiveStorage.xml</value>
    </property>
	
	<!-- 数据输出到HDFS路径 非分区表 -->
    <property>
        <name>hc1.hdfs</name>
        <value>/files/20200217/product_tf/dw/</value>
    </property>
	<!-- 数据输出到HDFS路径 分区表(P) -->
    <property>
        <name>hcP1.hdfs</name>
        <value>/files/20200217/product_tf/ods/</value>
    </property>
    
	<!-- 分区表的分区字段 如果有时间变量 使用{{timestamp}}占位 -->
    <property>
        <name>hcP1.part</name>
        <value>part_log_day={{timestamp}}</value>
    </property>
	<!-- 如果分区表的分区字段有时间变量 用来设置时间格式 -->
	<property>
        <name>hcP1.part.timestamp</name>
        <value>yyyy-MM-dd</value>
    </property>

    <!-- 数据处理中的临时文件 -->
    <property>
        <name>mr.data.process.other</name>
        <value>/hive_process/other_one/product/</value>
    </property>

    <!-- 导入数据时是否启用查询条件 默认true -->
    <property>
        <name>import.db.connection.open</name>
        <value>true</value>
    </property>

    <!-- 构建切片时，是否启用查询条件 -->
    <property>
        <name>create.spliter.isCondition</name>
        <value>false</value>
    </property>

	<!-- 构建切片时，每个map-task的数据量 -->
    <property>
        <name>map.task.batch.count</name>
        <value>3000000</value>
    </property>

	<!-- 非分区表数据输出的临时目录后缀 -->
	<property>
		<name>export.ods.bak.dir</name>
		<value>_export</value>
	</property>
	
	<!-- 是否开启忽略查询条件 全量导入数据 默认是false -->
	<property>
		<name>is.conditions.full.dose.day</name>
		<value>true</value>
	</property>
	<!-- 如果忽略查询条件，倒是导入数据的时期是每个月的哪天 -->
	<property>
		<name>conditions.full.dose.day</name>
		<value>05</value>
	</property>

	<!-- mapreduce任务名的后缀 -->
	<property>
		<name>job.name.db</name>
		<value>jlc_ods</value>
	</property>

	<!-- 数据压缩 -->
	<property>
		<name>file.output.compress</name>
		<value>none</value>
	</property>

	<!-- ======mapreduce配置项====== -->
	<property>
        <name>mapreduce.job.queuename</name>
        <value>xstorm</value>
    </property>

    <property>
        <name>mapred.job.map.capacity</name>
        <value>100</value>
    </property>

    <property>
        <name>mapred.job.reduce.capacity</name>
        <value>100</value>
    </property>
	
	<property>
		<name>mapreduce.map.memory.mb</name>
		<value>4096</value>
	</property>

	<property>
		<name>mapreduce.reduce.memory.mb</name>
		<value>4096</value>
	</property>
	
	<property>
        <name>mapreduce.job.running.map.limit</name>
        <value>300</value>
    </property>
    <property>
        <name>mapreduce.job.running.reduce.limit</name>
        <value>300</value>
    </property> 

</configuration>