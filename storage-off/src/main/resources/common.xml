<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- 导入数据的源数据库及库表 配置文件 -->
    <property>
        <name>import.db.config.path</name>
        <value>/server/app/mr/product/ImportConfig.xml</value>
    </property>

	<!-- 数据输出配置项 -->
	<property>
        <name>load.hive.config</name>
        <value>hc1,hcP1</value>
    </property>

	<!-- 数据输出到Hive的Location 配置文件 非分区表 -->
	<property>
        <name>hc1.hive</name>
        <value>/server/app/mr/product/LoadToHiveODS.xml</value>
    </property>
	<!-- 数据输出到Hive的Location 配置文件 分区表(P) -->
    <property>
        <name>hcP1.hive</name>
        <value>/server/app/mr/product/LoadToHiveStorage.xml</value>
    </property>
	
	<!-- 数据输出到HDFS路径 非分区表 -->
    <property>
        <name>hc1.hdfs</name>
        <value>/files/20200217/product_tf/dw/</value>
    </property>
	<!-- 数据输出到HDFS路径 分区表(P) -->
    <property>
        <name>hcP1.hdfs</name>
        <value>/files/20200217/product_tf/ods/</value>
    </property>

	<!-- 分区表的分区字段 如果有时间变量 使用{{timestamp}}占位 -->
    <property>
        <name>hcP1.part</name>
        <value>part_log_day={{timestamp}}</value>
    </property>
	<!-- 如果分区表的分区字段有时间变量 用来设置时间格式 -->
	<property>
        <name>hcP1.part.timestamp.format</name>
        <value>yyyy-MM-dd</value>
    </property>

    <!-- 数据处理中的临时文件目录 -->
    <property>
        <name>mr.data.process.other</name>
        <value>/hive_process/other_one/product/</value>
    </property>
    
    <!-- 数据处理中的进度文件目录 -->
    <property>
        <name>mr.data.process.plan</name>
        <value>/hive_process/plan/product/</value>
    </property>

    <!-- 导入数据时是否启用查询条件 默认true -->
    <property>
        <name>import.db.connection.open</name>
        <value>true</value>
    </property>

    <!-- 构建切片时，是否启用查询条件 -->
    <property>
        <name>create.spliter.isCondition</name>
        <value>false</value>
    </property>

	<!-- 构建切片时，每个map-task的数据量 -->
    <property>
        <name>map.task.batch.count</name>
        <value>3000000</value>
    </property>

	<!-- 是否开启忽略查询条件 全量导入数据 默认是false -->
	<property>
		<name>is.conditions.full.dose.day</name>
		<value>true</value>
	</property>
	<!-- 如果忽略查询条件，倒是导入数据的时期是每个月的哪天 -->
	<property>
		<name>conditions.full.dose.day</name>
		<value>05</value>
	</property>

	<!-- mapreduce任务名的后缀 -->
	<property>
		<name>job.name.unique</name>
		<value>product</value>
	</property>
	
	<!-- 任务在配置时间范围内只可单次运行 -->
	<property>
		<name>job.execute.multiple.format</name>
		<value>yyyyMMdd</value>
	</property>
	
	<!-- 数据导入表的黑名单 -->
	<property>
        <name>import.db.blacklist.path</name>
        <value>/server/app/mr/product/blackList.txt</value>
    </property>
    
    <!-- 数据导入表的黑名单过滤字符串 -->
    <property>
        <name>import.db.blacklist.filter</name>
        <value>bak</value>
    </property>

	<!-- 数据压缩 -->
	<property>
		<name>file.output.compress</name>
		<value>none</value>
	</property>
	
	<!-- HiveServer2 Driver -->
	<property>
		<name>hive.connection.driver</name>
		<value>org.apache.hive.jdbc.HiveDriver</value>
	</property>
	<!-- HiveServer2 URL -->
	<property>
		<name>hive.connection.url</name>
		<value>jdbc:hive2://dservice06.prod.data.phd2.jianlc.jlc:10000;ssl=true;sslTrustStore=/var/run/cloudera-scm-agent/process/2179-hue-HUE_SERVER/cm-auto-global_truststore.jks;trustStorePassword=R2j5DkgDZVvjTziNMNjuyvSB9pVBeFzRkKCmU4LfBuN/</value>
	</property>
	<!-- HiveServer2 UserName -->
	<property>
		<name>hive.connection.username</name>
		<value></value>
	</property>
	<!-- HiveServer2 PassWord -->
	<property>
		<name>hive.connection.password</name>
		<value></value>
	</property>
	
	<property>
		<name>redis.host</name>
		<value></value>
	</property>
	<property>
		<name>redis.port</name>
		<value></value>
	</property>
	<property>
		<name>redis.password</name>
		<value></value>
	</property>
	
	<!-- ======MapReduce配置项====== -->
	<property>
        <name>mapreduce.job.queuename</name>
        <value>xstorm</value>
    </property>

    <property>
        <name>mapred.job.map.capacity</name>
        <value>100</value>
    </property>

    <property>
        <name>mapred.job.reduce.capacity</name>
        <value>100</value>
    </property>
	
	<property>
		<name>mapreduce.map.memory.mb</name>
		<value>4096</value>
	</property>

	<property>
		<name>mapreduce.reduce.memory.mb</name>
		<value>4096</value>
	</property>
	
	<property>
        <name>mapreduce.job.running.map.limit</name>
        <value>300</value>
    </property>
    <property>
        <name>mapreduce.job.running.reduce.limit</name>
        <value>300</value>
    </property> 
    
    <!-- ======Hive配置项====== -->
    <property>
	    <name>hive.metastore.uris</name>
	    <value>thrift://dservice02.prod.data.phd2.jianlc.jlc:9083,thrift://dservice06.prod.data.phd2.jianlc.jlc:9083</value>
	</property>

</configuration>